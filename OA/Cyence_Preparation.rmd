---
title: "Cyence Data Exercise"
author: "Yiming Gao"
date: "2/18/2018"
output:
  html_document:
    theme: readable
---

## Introductions
https://rpubs.com/ryankelly/reg
### Cyber Risk
Cyber risk, a new category of risk, is emerging in recent years. Cyence is focusing on assessing cyber risk, using machine learning and statistical methods to quantify cyber risk for everyday financial situations.

Most insurers can only write policies with low liability that don't begin to cover the potential financial loss of a hack. Most insurance is underwritten based upon historical data. However, cyber is different. Historical data is not predictive in the cyber world because the parties involved are dynamic: hackers are constantly improving their methods, and organizations are always working to strengthen their networks.

### How Cyence Works
The Cyence collects a variety of data and processes it through a data science framework which combines both machine learning and econometric models.

Target: predict the incidence of a cyber event (regression/ classification?), evaluate the severity, accumulation, and exposure of a particular policy.

### Machine Learning in Cyber Security
We are trying to use machine learning to **find anomalies**. More precisely we use it to identify malicious behavior or entites: hackers, attackers, malware, etc. One of the biggest challenges is to define what's normal.
- Malware identification (deep learning)

Sometimes we don't have great training data because some datasets are significantly biased. Turns out, in cyber security, we mostly deal with categorical data (urls, usernames, IPs, ports, etc.)

**Unsupervised Learning** methods such as dimensionality reduction and association rules don't really bring us any closer to finding anomalies in our data set. They help us group data records, such as network traffic. **Clustering** could be interesting to find anomalies. Maybe we can find ways to cluster "normal" and "abnormal" entities, such as users or devices. (http://raffy.ch/blog/2017/10/22/unsupervised-machine-learning-in-cyber-security/)


- t-SNE

### Context and Knowledge
Rather than looking at the network traffic logs in isolation, we need to add context to make sense of the data. Is a device supposed to respond to DNS queries? If we know that it is a DNS server, this is absolutely normal behavior, but if not, that could be a sign of an attack.

## Exploratory Data Analysis
First I load some necessary libraries and define an evaluation function as well as a function to extract the best result from a caret object.

```{r, message=FALSE, warning=FALSE}
library(readr)
library(caret)
library(MASS)
library(Rtsne)
library(nnet)
library(tidyverse)
library(anomalyDetection)
library(pROC)
library(mlbench)
library(mice)
library(Hmisc) # Imputation missing values with mean/ median/ mode

# accuracy function
accuracy <- function(actual, predicted) {
  mean(actual == predicted)
}

# extract the row with the best tuning parameters
get_best_result = function(caret_fit) {
  best_result = caret_fit$results[as.numeric(rownames(caret_fit$bestTune)), ]
  rownames(best_result) = NULL
  best_result
}
```

Since there are some categorical variables in our dataset, I decided to transform some of them. (https://stats.idre.ucla.edu/r/modules/coding-for-categorical-variables-in-regression-models/)

```{r}
# Transform categorical data
```

Check missing values
```{r}
# sapply(dataset, function(x) sum(is.na(x)))
# Hmisc Imputation


# KNN Imputation
library(DMwR)
a = head(BostonHousing)
a$ptratio[5] = NA
knnImputation(a[, !names(BostonHousing) %in% "medv"], k = 3)  # perform knn imputation.
```

Training test split
- Deal with unbalanced data: https://www.r-bloggers.com/dealing-with-unbalanced-data-in-machine-learning/
```{r}
set.seed(218)
index = createDataPartition(dataset$label, p = 0.7, list = FALSE)
dataset_trn = dataset[index, ]
dataset_tst = dataset[-index, ]
table(dataset$label)

# Cross validation
cv_5 = trainControl(method = "cv", number = 5)

# Original model
model_rf = train(label ~.,
                 data = dataset_trn,
                 method = "rf",
                 preProcess = c("scale", "center"),
                 trControl = cv_5,
                 verboseIter = FALSE)

# Undersampling
model_rf = train(label ~.,
                 data = dataset_trn,
                 method = "rf",
                 preProcess = c("scale", "center"),
                 trControl = cv_5,
                 verboseIter = FALSE,
                 sampling = "down") # or "up"
```



## Feature Engineering
The goal of this feature engineering is to extract the maximum information from the available features so as to maximize our ability to predict or categorize unknown data.

### Data Visualization
The response variable is `label` and takes values `` and ``. There are  predictors in our dataset, so we first explore the relationship of those feature variables with the response variable.
```{r, echo=FALSE, fig.align="c", fig.height=9, fig.width=12, message=FALSE}
featurePlot(x = voice_trn[, 1: 20], 
            y = voice_trn$label,
            plot = "density", 
            ## Pass in options to xyplot() to 
            ## make it prettier
            scales = list(x = list(relation = "free"), 
                          y = list(relation = "free")), 
            adjust = 1.5, 
            pch = "|", 
            layout = c(5, 4), 
            auto.key = list(columns = 2))
```


**Unsupervised learning** refers to algorithms provided with unlabeled training data, with the task of inferring the categories all by itself. For example, consider the case of network flow data. Given how good machines are at finding patterns in large datasets, it is often much easier to simply have the machine separate data into groups for us.

### Variable Selection
In this part I try to do some variable selection before building up and comparing the models.

First, I fit a boosted tree model and create a plot showing feature importance.
```{r, fig.align="c", fig.height=8, message=FALSE, warning=FALSE}
gbm_grid = expand.grid(interaction.depth = c(1, 2),
                       n.trees = c(500, 1000, 1500),
                       shrinkage = c(0.001, 0.01, 0.1),
                       n.minobsinnode = 10)

voice_gbm = train(label ~ ., data = voice_trn, 
                  method = "gbm",
                  trControl = cv_5,
                  verbose = FALSE,
                  tuneGrid = gbm_grid)

voice_var_imp = summary(voice_gbm)

head(voice_var_imp)
```

Here we see the most important variables are XXX.

On the other hand, I try to construct a Learner Vector Quantization (LVQ) model. The varImp is then used to estimate the variable importance, which is printed and plotted. (LVQ is best understood as a classification algorithm)

```{r}
data("PimaIndiansDiabetes")

# Calculate correlation matrix
Corr = cor(PimaIndiansDiabetes[, 1:8])
print(round(Corr, digits = 3))

# Find features that are highly correlated (ideally > 0.75, here = 0.5)
highly_Corr = sort(findCorrelation(Corr, cutoff = 0.3))
reduced_data = PimaIndiansDiabetes[, -c(highly_Corr)]

model = train(diabetes~.,data=PimaIndiansDiabetes, method="rf", preProcess="scale", trControl=cv_5)

# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)

```


### Hierarchical Clustering
https://www.r-bloggers.com/hierarchical-clustering-in-r-2/
```{r}
library(sparcl)

# average linkage, scaling
hc = hclust(dist(scale(iris[, 3:4])), method = "average")
hcut = cutree(hc, 3)

ColorDendrogram(hc, y = hcut,
                labels = names(hcut),
                main = "Average Linkage, scaling",
                branchlength = 0.62)
```



### K-means Clustering
```{r}
tot_withinss = rep(0, 15)

for (i in 1:15) {
  kmean = kmeans(clust, centers = i, nstart = 10)
  tot_withinss[i] = kmean$tot.withinss
}

plot(1: 15, tot_withinss, pch = 20, type = "o", col = "dodgerblue2", xlab = "Number of clusters", ylab = "tot.withinss")
grid()

# The elbow occurs at 4, we may consider keeping first 4 clusters.
```

### Principal Component Analysis
The principal components are supplied with normalized version of original predictors. This is because, the original predictors may have different scales.

```{r}
data(iris)
head(iris, 3)

# log transformation of the variables
log.ir = log(iris[, 1:4])
ir.labels = iris[, 5]

# Since road_type, algorithm are categorical, we convert them into numeric using one hot encoding
#create a dummy data frame
new_datas2 = cbind(dummy.data.frame(datas2, names = c("road_type", "algorithm")), datas2[c("road_type", "algorithm")])

```


```{r, message=FALSE, warning=FALSE}
library(dummies)
library(factoextra)

# Normalization
prin_comp = prcomp(log.ir, center = TRUE, scale. = TRUE)
prin_comp$rotation

# Eigenvalues
eig = (prin_comp$sdev)^2

# Variances 
variance = eig / sum(eig)

# Cumulative variances
cumvar = cumsum(variance)
prin_comp_active = data.frame(eig = eig, variance = variance, cumvariance = cumvar)

# scree plot using factoextra package
fviz_screeplot(prin_comp, addlabels = TRUE, hjust = -0.3, linecolor = "firebrick1")

# comulative scree plot
plot(cumsum(variance), xlab = "Principal Component", ylab = "Cumulative Proportion of Variance Explained", main = "Cumulative Scree Plot",
     type = "b", col = "dodgerblue2", xaxt = "n", yaxt  = "n")
axis(1, at = seq(1, 4), las = 1)
axis(2, at = seq(0, 1, 0.1), las = 1)
grid()
```

Visualization of Components
```{r}
# Helper function:
# Correlation between variables and principal components
var_cor_func <- function(var.loadings, comp.sdev) {
  var.loadings * comp.sdev
}

# Variable correlation / coordinates
loadings = prin_comp$rotation
sdev = prin_comp$sdev
var.coord <- var.cor <- t(apply(loadings, 1, var_cor_func, sdev))
head(var.coord[, 1:4])

# Contributions of the variables to the principal components
var.cos2 = var.coord^2
comp.cos2 = apply(var.cos2, 2, sum)
contrib = function(var.cos2, comp.cos2) {var.cos2 * 100 / comp.cos2}
var.contrib = t(apply(var.cos2, 1, contrib, comp.cos2))

# Highlight the most important (i.e. contributing variables)
fviz_pca_var(prin_comp, col.var = "contrib") +
  scale_color_gradient2(low = "white", mid = "blue", high = "red", midpoint = 25) + 
  theme_minimal() # PC1 and PC2
```

Transform original data

It is possible to first apply a Box-Cox transformation to correct for skewness, center and scale each variable and then apply PCA in one call to the `preProcess` function of the `caret` package.

```{r}
require(caret)
trans = preProcess(iris[, 1:4], method = c("BoxCox", 
                                           "center",
                                           "scale",
                                           "pca"))
PC = predict(trans, iris[, 1:4])
head(PC)
```


### T-distributed Stochastic Neighbor Embedding
T-SNE is a non-linear dimensionality reduction algorithm finds patterns in the data by identifying observed clusters based on similarity of data points with multiple features. But it is not a clustering algorithm it is a dimensionality reduction algorithm. This is because it maps the multi-dimensional data to a lower dimensional space, the input features are no longer identifiable. Thus you cannot make any inference based only on the output of t-SNE. So essentially it is mainly a data exploration and visualization technique.

```{r}
train = read.csv("train.csv")
labels = as.factor(train$label)

# For plotting
colors = rainbow(length(unique(train$label)))
names(colors) = unique(train$label)

# TSNE on data
tsne = Rtsne(train[, -1], dims = 2, perplexity = 30, verbose = TRUE, max_iter = 500)

# plotting
plot(tsne$Y, t = "n", main = "tsne")
text(tsne$Y, labels = train$label, col = colors[train$label])
```


### Unbalanced Data
Unbalanced data refers to classification problems where we have unequal instances for different classes. We can
- Under-sampling
- Over-sampling

## Model Building
- Logistic Regression
- K-Nearest Neighbors (KNN)
- Naive Bayes
- Decision Tree
- Support Vector Machine (SVM)
- Multilayer Perceptron Neural Network (MIP)

```{r}
# Logistic Regression
model_logistic = train(label~.,
                       data = dataset_trn,
                       trControl = cv_5,
                       method = "glm",
                       family = "binomial")

# prediction
head(predict(model_logistic, newdata = dataset_tst))
```


```{r}
# KNN with tuning
model_knn = train(label ~ .,
                  data = dataset_trn,
                  method = "knn",
                  trControl = cv_5,
                  preProcess = c("center", "scale"),
                  tuneGrid = expand.grid(k = seq(1, 11, by = 2)))

plot(model_knn)

get_best_result(model_knn)
```

```{r}
# SVM with a linear kernel
lin_grid = expand.grid(C = c(2 ^ (-5:5)))

svm_lin = train(Purchase ~ ., data = oj_trn, 
                method = "svmLinear",
                trControl = cv_5,
                tuneGrid = lin_grid)

svm_lin_acc = round(accuracy(oj_tst$Purchase, predict(svm_lin, oj_tst)), 4)
svm_best_lin = get_best_result(svm_lin)

# confusion matrix
table(oj_tst$Purchase, predict(svm_poly, oj_tst))
```

### Prediction

### Evaluation

```{r}
# ROC
library(mlbench)
data(Sonar)

ctrl <- trainControl(method="cv", 
                     summaryFunction=twoClassSummary, 
                     classProbs=T,
                     savePredictions = T)
rfFit <- train(Class ~ ., data=Sonar, 
               method="rf", preProc=c("center", "scale"), 
               trControl=ctrl)

# Select a parameter setting
selectedIndices <- rfFit$pred$mtry == 2

# Plot:
plot.roc(rfFit$pred$obs[selectedIndices],
         rfFit$pred$M[selectedIndices])
```


| Model  | Accuracy |
|:----------:|---------|
| Single   | No      |
| Average  | No      |
| Complete | No      |
| Single   | Yes     |
| Average  | Yes     |
| Complete | Yes     |

## Future Work
If I were given more time, 



## Sidenotes
These are some of my analysis and thoughts of the dataset. I'm not sure if these make sense because of the limit of my background knowledge. But I'm a quick learner and more than willing to accept new knowledge. 

Please don’t hesitate to share any insights with me no matter you’d like to proceed my application or not, I would be really appreciated!
